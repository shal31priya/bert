{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">BERT tutorial: Classify spam vs no spam emails</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded in comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_text\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtext\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow_hub/__init__.py:111\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    104\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to import tf_keras. Please note that tf_keras is not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m installed by default when you install tensorflow_hub. This is so\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m that users can decide which tf_keras package to use. To use\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m tensorflow_hub, please install a current version of tf_keras.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m       )\n\u001b[1;32m    109\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m _ensure_keras_2_importable()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Symbols exposed via tensorflow_hub.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLayer\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow_hub/__init__.py:97\u001b[0m, in \u001b[0;36m_ensure_keras_2_importable\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that Keras 2 can be used by attempting to import tf_keras.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mRaises:\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m  ImportError: if using tf.keras would mean using Keras 3 and tf_keras is not\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    installed.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m version_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(tf\u001b[38;5;241m.\u001b[39mkeras, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version_fn \u001b[38;5;129;01mand\u001b[39;00m version_fn()\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/lazy_loader.py:182\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_initialized:\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_keras_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_3\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\n\u001b[1;32m    186\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat.v1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m   ):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` is not available with Keras 3. Keras 3 has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno support for TF 1 APIs. You can install the `tf_keras` package \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` to `tf_keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/lazy_loader.py:182\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_initialized:\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_keras_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_3\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\n\u001b[1;32m    186\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat.v1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m   ):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` is not available with Keras 3. Keras 3 has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno support for TF 1 APIs. You can install the `tf_keras` package \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` to `tf_keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m     )\n",
      "    \u001b[0;31m[... skipping similar frames: KerasLazyLoader.__getattr__ at line 182 (2961 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/lazy_loader.py:182\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_initialized:\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_keras_version \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras_3\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    183\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    185\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_submodule\n\u001b[1;32m    186\u001b[0m       \u001b[38;5;129;01mand\u001b[39;00m item\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompat.v1.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m   ):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` is not available with Keras 3. Keras 3 has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno support for TF 1 APIs. You can install the `tf_keras` package \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.compat.v1.keras` to `tf_keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/lazy_loader.py:178\u001b[0m, in \u001b[0;36mKerasLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m--> 178\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_tfll_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_tfll_initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_tfll_name\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(types\u001b[38;5;241m.\u001b[39mModuleType, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)\n\u001b[1;32m    180\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfll_initialized:\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded in comparison"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-hub\n",
      "  Using cached tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow-hub) (2.1.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow-hub) (5.29.0)\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub)\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (23.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.68.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.38.4)\n",
      "Requirement already satisfied: rich in /Users/shalini/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (14.0.0)\n",
      "Requirement already satisfied: namex in /Users/shalini/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/shalini/anaconda3/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.0)\n",
      "Using cached tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras, tensorflow-hub\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [tensorflow-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed tensorflow-hub-0.16.1 tf-keras-2.19.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly\n",
      "  Downloading tf_nightly-2.20.0.dev20250607-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (23.1)\n",
      "Requirement already satisfied: protobuf>=4.21.6 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (1.68.1)\n",
      "Collecting tb-nightly~=2.19.0.a (from tf-nightly)\n",
      "  Downloading tb_nightly-2.19.0a20250218-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras-nightly>=3.6.0.dev (from tf-nightly)\n",
      "  Downloading keras_nightly-3.10.0.dev2025060703-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (3.14.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tf-nightly) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tf-nightly) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tf-nightly) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tf-nightly) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tf-nightly) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tb-nightly~=2.19.0.a->tf-nightly) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tb-nightly~=2.19.0.a->tf-nightly) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tb-nightly~=2.19.0.a->tf-nightly) (2.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tf-nightly) (0.38.4)\n",
      "Requirement already satisfied: rich in /Users/shalini/anaconda3/lib/python3.11/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (14.0.0)\n",
      "Requirement already satisfied: namex in /Users/shalini/anaconda3/lib/python3.11/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.1.0)\n",
      "Requirement already satisfied: optree in /Users/shalini/anaconda3/lib/python3.11/site-packages (from keras-nightly>=3.6.0.dev->tf-nightly) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tb-nightly~=2.19.0.a->tf-nightly) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from rich->keras-nightly>=3.6.0.dev->tf-nightly) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras-nightly>=3.6.0.dev->tf-nightly) (0.1.0)\n",
      "Downloading tf_nightly-2.20.0.dev20250607-cp311-cp311-macosx_12_0_arm64.whl (195.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.3/195.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tb_nightly-2.19.0a20250218-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras_nightly-3.10.0.dev2025060703-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tb-nightly, keras-nightly, tf-nightly\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [tf-nightly]3\u001b[0m [tf-nightly]ly]\n",
      "\u001b[1A\u001b[2KSuccessfully installed keras-nightly-3.10.0.dev2025060703 tb-nightly-2.19.0a20250218 tf-nightly-2.20.0.dev20250607\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.68.1)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.1.3-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from tensorboard~=2.19.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.16.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/shalini/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp311-cp311-macosx_12_0_arm64.whl (252.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-macosx_10_9_universal2.whl (671 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.4/671.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp311-cp311-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-macosx_12_0_arm64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp311-cp311-macosx_11_0_arm64.whl (338 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, optree, opt-einsum, numpy, google-pasta, gast, astunparse, tensorboard, rich, ml-dtypes, h5py, keras, tensorflow\n",
      "\u001b[2K  Attempting uninstall: numpy0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [tensorflow-io-gcs-filesystem]\n",
      "\u001b[2K    Found existing installation: numpy 1.24.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/17\u001b[0m [tensorflow-io-gcs-filesystem]\n",
      "\u001b[2K    Uninstalling numpy-1.24.3:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]-io-gcs-filesystem]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.24.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: tensorboard[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: tensorboard 2.18.0━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling tensorboard-2.18.0:90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled tensorboard-2.18.0━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/17\u001b[0m [numpy]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K  Attempting uninstall: h5py━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [ml-dtypes]d]\n",
      "\u001b[2K    Found existing installation: h5py 3.9.0╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [ml-dtypes]\n",
      "\u001b[2K    Uninstalling h5py-3.9.0:━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [ml-dtypes]\n",
      "\u001b[2K      Successfully uninstalled h5py-3.9.01m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m13/17\u001b[0m [ml-dtypes]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [tensorflow]7\u001b[0m [tensorflow]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 2.1.3 which is incompatible.\n",
      "recbole 1.2.0 requires colorama==0.4.4, but you have colorama 0.4.6 which is incompatible.\n",
      "transformers 4.36.2 requires huggingface-hub<1.0,>=0.19.3, but you have huggingface-hub 0.17.3 which is incompatible.\n",
      "transformers 4.36.2 requires tokenizers<0.19,>=0.14, but you have tokenizers 0.13.2 which is incompatible.\n",
      "scipy 1.11.1 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.1.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 h5py-3.14.0 keras-3.10.0 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.1.0 numpy-2.1.3 opt-einsum-3.4.0 optree-0.16.0 rich-14.0.0 tensorboard-2.19.0 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import the dataset (Dataset is taken from kaggle)</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>641</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Message                                                            \\\n",
       "           count unique                                                top   \n",
       "Category                                                                     \n",
       "ham         4825   4516                             Sorry, I'll call later   \n",
       "spam         747    641  Please call our customer service representativ...   \n",
       "\n",
       "               \n",
       "         freq  \n",
       "Category       \n",
       "ham        30  \n",
       "spam        4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15481865284974095"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "747/4825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15% spam emails, 85% ham emails: This indicates class imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam = df[df['Category']=='spam']\n",
    "df_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4825, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham = df[df['Category']=='ham']\n",
    "df_ham.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(747, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ham_downsampled = df_ham.sample(df_spam.shape[0])\n",
    "df_ham_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1494, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_ham_downsampled, df_spam])\n",
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam    747\n",
       "ham     747\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>ham</td>\n",
       "      <td>We can go 4 e normal pilates after our intro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>spam</td>\n",
       "      <td>accordingly. I repeat, just text the word ok o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>ham</td>\n",
       "      <td>Guess which pub im in? Im as happy as a pig in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>ham</td>\n",
       "      <td>You in your room? I need a few</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message  spam\n",
       "4925      ham    We can go 4 e normal pilates after our intro...     0\n",
       "4249     spam  accordingly. I repeat, just text the word ok o...     1\n",
       "5006      ham  Guess which pub im in? Im as happy as a pig in...     0\n",
       "2567      ham                     You in your room? I need a few     0\n",
       "14        ham                I HAVE A DATE ON SUNDAY WITH WILL!!     0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['spam']=df_balanced['Category'].apply(lambda x: 1 if x=='spam' else 0)\n",
    "df_balanced.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Split it into training and test data set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced['Message'],df_balanced['spam'], stratify=df_balanced['spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3354    I emailed yifeng my part oredi.. Can ü get it ...\n",
       "466     great princess! I love giving and receiving or...\n",
       "4154    URGENT!! Your 4* Costa Del Sol Holiday or £500...\n",
       "3162    Mystery solved! Just opened my email and he's ...\n",
       "Name: Message, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now lets import BERT model and get embeding vectors for few sample statements</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\n",
       "array([[-0.8435169 , -0.51327276, -0.8884574 , ..., -0.74748874,\n",
       "        -0.75314736,  0.91964483],\n",
       "       [-0.87208366, -0.50543964, -0.94446677, ..., -0.858475  ,\n",
       "        -0.7174535 ,  0.8808298 ]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocess(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']\n",
    "\n",
    "get_sentence_embeding([\n",
    "    \"500$ discount. hurry up\", \n",
    "    \"Bhavin, are you up for a volleybal game tomorrow?\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Get embeding vectors for few sample words. Compare them using cosine similarity</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = get_sentence_embeding([\n",
    "    \"banana\", \n",
    "    \"grapes\",\n",
    "    \"mango\",\n",
    "    \"jeff bezos\",\n",
    "    \"elon musk\",\n",
    "    \"bill gates\"\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9911089]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity([e[0]],[e[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values near to 1 means they are similar. 0 means they are very different.\n",
    "Above you can use comparing \"banana\" vs \"grapes\" you get 0.99 similarity as they both are fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8470385]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([e[0]],[e[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing banana with jeff bezos you still get 0.84 but it is not as close as 0.99 that we got with grapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98720354]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([e[3]],[e[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeff bezos and Elon musk are more similar then Jeff bezos and banana as indicated above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Build Model</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of models you can build in tensorflow. \n",
    "\n",
    "(1) Sequential\n",
    "(2) Functional\n",
    "\n",
    "So far we have built sequential model. But below we will build functional model. More information on these two is here: https://becominghuman.ai/sequential-vs-functional-model-in-keras-20684f766057"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/47605558/importerror-failed-to-import-pydot-you-must-install-pydot-and-graphviz-for-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        {'input_mask': (None 0           text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_1 (KerasLayer)      {'default': (None, 7 109482241   keras_layer[0][0]                \n",
      "                                                                 keras_layer[0][1]                \n",
      "                                                                 keras_layer[0][2]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           keras_layer_1[0][13]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            769         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 109,483,010\n",
      "Trainable params: 769\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Train the model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 7s 189ms/step - loss: 0.3398 - accuracy: 0.8857 - precision: 0.8750 - recall: 0.9000 2s - loss: 0.3473 - accuracy: 0.8854 - precision: 0.8672 -\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 6s 185ms/step - loss: 0.3271 - accuracy: 0.8857 - precision: 0.8649 - recall: 0.9143\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 7s 187ms/step - loss: 0.3093 - accuracy: 0.8920 - precision: 0.8844 - recall: 0.9018\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 7s 187ms/step - loss: 0.2920 - accuracy: 0.9071 - precision: 0.8986 - recall: 0.9179\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 7s 187ms/step - loss: 0.2837 - accuracy: 0.9098 - precision: 0.9076 - recall: 0.9125\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 7s 187ms/step - loss: 0.2741 - accuracy: 0.9062 - precision: 0.9027 - recall: 0.9107\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 7s 189ms/step - loss: 0.2643 - accuracy: 0.9089 - precision: 0.8962 - recall: 0.9250 4s - loss: 0.2845 - accuracy: 0.8924 - precisi\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 7s 186ms/step - loss: 0.2570 - accuracy: 0.9161 - precision: 0.9161 - recall: 0.9161\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 7s 196ms/step - loss: 0.2512 - accuracy: 0.9134 - precision: 0.9026 - recall: 0.9268\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 7s 193ms/step - loss: 0.2419 - accuracy: 0.9179 - precision: 0.9239 - recall: 0.9107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1db822fcf70>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 4s 194ms/step - loss: 0.2600 - accuracy: 0.9064 - precision: 0.8486 - recall: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2599719762802124,\n",
       " 0.9064171314239502,\n",
       " 0.8486238718032837,\n",
       " 0.9893048405647278]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "y_predicted = y_predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_predicted = np.where(y_predicted > 0.5, 1, 0)\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[154,  33],\n",
       "       [  2, 185]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.heatmap(cm, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90       187\n",
      "           1       0.85      0.99      0.91       187\n",
      "\n",
      "    accuracy                           0.91       374\n",
      "   macro avg       0.92      0.91      0.91       374\n",
      "weighted avg       0.92      0.91      0.91       374\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Inference</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8734353 ],\n",
       "       [0.92858446],\n",
       "       [0.8960864 ],\n",
       "       [0.29311982],\n",
       "       [0.13262196]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\n",
    "    'Enter a chance to win $5000, hurry up, offer valid until march 31, 2021',\n",
    "    'You are awarded a SiPix Digital Camera! call 09061221061 from landline. Delivery within 28days. T Cs Box177. M221BP. 2yr warranty. 150ppm. 16 . p pÂ£3.99',\n",
    "    'it to 80488. Your 500 free text messages are valid until 31 December 2005.',\n",
    "    'Hey Sam, Are you coming for a cricket game tomorrow',\n",
    "    \"Why don't you wait 'til at least wednesday to see if you get your .\"\n",
    "]\n",
    "model.predict(reviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
